# Alert Rules Configuration
#
# This file defines alert rules for monitoring the AHSP application.
# Compatible with Prometheus Alertmanager, Grafana, or similar tools.
#
# Severity Levels:
# - critical: Immediate action required (PagerDuty/Phone)
# - warning: Attention needed (Slack/Email)
# - info: Informational (Email)

groups:
  - name: ahsp_application_alerts
    interval: 1m
    rules:
      # ================================================================
      # Critical Alerts (Immediate Action Required)
      # ================================================================

      - alert: HighErrorRate
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m]) /
            rate(http_requests_total[5m])
          ) * 100 > 5
        for: 5m
        labels:
          severity: critical
          component: application
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}. Threshold is 5%."
          runbook: "https://wiki.example.com/runbooks/high-error-rate"

      - alert: HealthCheckFailure
        expr: health_check_status == 0
        for: 2m
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Health check failing"
          description: "Application health check has been failing for 2 minutes."
          runbook: "https://wiki.example.com/runbooks/health-check-failure"

      - alert: DatabaseConnectionFailure
        expr: db_connection_status == 0
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "Database connection lost"
          description: "Cannot connect to database."
          runbook: "https://wiki.example.com/runbooks/database-connection"

      - alert: RedisConnectionFailure
        expr: redis_connection_status == 0
        for: 1m
        labels:
          severity: critical
          component: cache
        annotations:
          summary: "Redis connection lost"
          description: "Cannot connect to Redis cache."
          runbook: "https://wiki.example.com/runbooks/redis-connection"

      - alert: ApplicationDown
        expr: up{job="ahsp-django"} == 0
        for: 2m
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Application is down"
          description: "AHSP application has been unreachable for 2 minutes."
          runbook: "https://wiki.example.com/runbooks/application-down"

      # ================================================================
      # Warning Alerts (Attention Needed)
      # ================================================================

      - alert: ElevatedErrorRate
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m]) /
            rate(http_requests_total[5m])
          ) * 100 > 1
        for: 10m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "Elevated error rate"
          description: "Error rate is {{ $value | humanizePercentage }}. Threshold is 1%."

      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 2
        for: 10m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "High response time (p95)"
          description: "95th percentile response time is {{ $value }}s. Threshold is 2s."

      - alert: HighRateLimitHits
        expr: rate(rate_limit_hits_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "High rate limit hits"
          description: "Rate limiting is being triggered {{ $value }} times per minute."

      - alert: LowCacheHitRate
        expr: |
          (
            cache_hits / (cache_hits + cache_misses)
          ) * 100 < 50
        for: 15m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value | humanizePercentage }}. Expected > 80%."

      - alert: HighDatabaseConnectionUsage
        expr: db_connection_pool_usage > 80
        for: 10m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "High database connection usage"
          description: "Database connection pool is {{ $value }}% utilized."

      - alert: SlowDatabaseQueries
        expr: rate(slow_query_count[5m]) > 10
        for: 10m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Slow database queries detected"
          description: "{{ $value }} slow queries per minute (> 1s)."

      - alert: ExcessiveDatabaseQueries
        expr: avg(db_queries_per_request) > 50
        for: 10m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "Excessive database queries per request"
          description: "Average {{ $value }} queries per request. Expected < 20."

      - alert: HighMemoryUsage
        expr: process_resident_memory_bytes / process_virtual_memory_max_bytes * 100 > 80
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }}."

      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total[5m]) * 100 > 70
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value | humanizePercentage }}."

      # ================================================================
      # Info Alerts (Informational)
      # ================================================================

      - alert: DeploymentCompleted
        expr: increase(deployment_event[5m]) > 0
        labels:
          severity: info
          component: deployment
        annotations:
          summary: "Deployment completed"
          description: "New version {{ $labels.version }} deployed."

      - alert: RateLimitingActive
        expr: rate(rate_limit_hits_total[1h]) > 0
        for: 1h
        labels:
          severity: info
          component: security
        annotations:
          summary: "Rate limiting is active"
          description: "Users are being rate limited. Monitor for abuse."

      # ================================================================
      # Business Metrics Alerts
      # ================================================================

      - alert: LowUserActivity
        expr: rate(active_users_count[1h]) < 5
        for: 2h
        labels:
          severity: info
          component: business
        annotations:
          summary: "Low user activity"
          description: "Only {{ $value }} active users in the last hour."

      - alert: HighExportFailureRate
        expr: |
          (
            rate(export_operations_total{status="failed"}[15m]) /
            rate(export_operations_total[15m])
          ) * 100 > 10
        for: 15m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "High export failure rate"
          description: "{{ $value | humanizePercentage }} of exports are failing."

      - alert: DeepCopyFailures
        expr: rate(deep_copy_operations{status="failed"}[15m]) > 5
        for: 10m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "Deep copy operations failing"
          description: "{{ $value }} deep copy operations failing per minute."

# ================================================================
# Alertmanager Configuration
# ================================================================

# alertmanager.yml
#
# route:
#   receiver: 'default-receiver'
#   group_by: ['alertname', 'cluster', 'service']
#   group_wait: 10s
#   group_interval: 10s
#   repeat_interval: 12h
#   routes:
#     - match:
#         severity: critical
#       receiver: pagerduty
#       continue: true
#     - match:
#         severity: warning
#       receiver: slack
#     - match:
#         severity: info
#       receiver: email
#
# receivers:
#   - name: 'pagerduty'
#     pagerduty_configs:
#       - service_key: '<pagerduty-service-key>'
#
#   - name: 'slack'
#     slack_configs:
#       - api_url: '<slack-webhook-url>'
#         channel: '#alerts'
#         title: 'AHSP Alert: {{ .GroupLabels.alertname }}'
#         text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
#
#   - name: 'email'
#     email_configs:
#       - to: 'team@example.com'
#         from: 'alerts@example.com'
#         smarthost: 'smtp.example.com:587'
#         auth_username: 'alerts@example.com'
#         auth_password: '<password>'

# ================================================================
# Usage Instructions
# ================================================================
#
# 1. Copy this file to your Prometheus configuration directory:
#    /etc/prometheus/rules/ahsp-alerts.yml
#
# 2. Add to prometheus.yml:
#    rule_files:
#      - "rules/ahsp-alerts.yml"
#
# 3. Configure alertmanager.yml with your notification channels
#
# 4. Reload Prometheus:
#    curl -X POST http://localhost:9090/-/reload
#
# 5. Test alerts:
#    - Trigger a test alert
#    - Verify notification received
#    - Document response procedures
